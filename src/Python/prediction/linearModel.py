import pandas as pd
import pickle
import os

import sklearn.linear_model as sklLM
from sklearn import metrics

__all__ = ["linear_model", "train_linear_model", "query_linear_model", "linear_model_to_java_code", "evaluate_linear_model"]

__current_working__dir = os.path.dirname(os.path.abspath(__file__))
lm_regressor_output = os.path.join(__current_working__dir,'lm_regressor.pkl')
linear_regressor_java = os.path.join(__current_working__dir,'../../Java/src/level_selection/model_representation/LinearRegressor.java')


""" Creates a linear model / orchestrates training and evaluation.

:param features_training    ->  training features
:param labels_training      ->  training labels
:param features_testing     ->  testing features
:param labels_testing       ->  testing labels
:param debug                ->  verbose debugging information

:return                     ->  predicted labels (scores)
"""
def linear_model(features_training, labels_training, features_testing, labels_testing, debug=False):
    lmreg = train_linear_model(features_training, labels_training)
    linear_model_to_java_code(lmreg, list(features_training.columns), linear_regressor_java, 'LinearRegressor')
    labels_predicted = query_linear_model(lmreg, features_testing)
    evaluate_linear_model(lmreg, labels_predicted, labels_testing, features_testing, debug)
    with open(lm_regressor_output, 'wb') as file:
        pickle.dump(lmreg, file)
    return labels_predicted


""" Trains a linear model.

:param features_training    ->  training features
:param labels_training      ->  training labels

:return                     ->  instance of a linear model
"""
def train_linear_model(features_training, labels_training):
    lmreg = sklLM.LinearRegression()
    lmreg.fit(features_training, labels_training)
    return lmreg


""" Queries a linear model.

:param lmreg            ->  instance of a linear model
:param features_testing ->  testing features

:return                     ->  predicted labels (scores)
"""
def query_linear_model(lmreg, features_testing):
    labels_predicted = lmreg.predict(features_testing)
    return labels_predicted


""" Converts a linear model to Java code.

:param model            ->  instance of a linear model
:param feature_names    ->  list of features known to the model
:param filepath         ->  Java output location
:param classname        ->  Java class
"""
def linear_model_to_java_code(model, feature_names, filepath, classname):
    with open(filepath, 'w') as file:
        coef_ = model.coef_
        file.write("// THIS FILE WAS AUTOMATICALLY GENERATED BY 'src/Python/decision_tree/decision_tree.py'\n\n")
        file.write("package level_selection.model_representation;\n\n")
        file.write("public class "+classname+" {\n")
        file.write("public static double[] predict({}) {{\n".format(", ".join(['int '+f for f in feature_names])))

        file.write("\treturn new double[] {{{}}};\n".format(' + '.join(["{}*{}\n\t\t".format(feature,coef_[i]) for i,feature in enumerate(feature_names)])))

        file.write("}\n}")


""" Evaluates a linear model and provides visualization. (#not finished)

:param lmreg            ->  instance of a linear model
:param labels_predicted ->  predicted labels (scores) by the model
:param labels_testing   ->  testing labels
:param features_testing ->  testing features
:param debug            ->  verbose debugging information
"""
def evaluate_linear_model(lmreg, labels_predicted, labels_testing, features_testing, debug=False):
    print("LM coefficients:", lmreg.coef_)
    print("Mean squared error: %.2f" % metrics.mean_squared_error(labels_testing, labels_predicted))
    print("Variance accounted for: %.2f" % metrics.r2_score(labels_testing, labels_predicted))

    pred_comp = pd.DataFrame()
    pred_comp['labels_testing'] = labels_testing
    pred_comp['labels_predicted'] = labels_predicted

    np_pred_comp = pred_comp.to_numpy()
    if debug:
        print(np_pred_comp)
        #plt.plot(np_pred_comp)
        #plt.show()

    # visualization of model performance // not finished
    max = 0
    observations = features_testing.shape[0]
    if isinstance(features_testing, pd.DataFrame):
        features = features_testing.copy()
        features['id'] = '-1'
        for elem in range(observations):
            features.loc[elem, 'id'] = elem

        sorted_features = pd.DataFrame()
        for elem in range(observations):
            # find current maximum
            for row in range(observations):
                if features['num_destroyable_objects'][row] > max:
                    max = features['num_destroyable_objects'][row]

        features = features.sort_values(by=['num_destroyable_objects'], inplace=True)
        # plt.scatter(features['num_destroyable_objects'], labels_testing, color="blue")
        # plt.plot(features['num_destroyable_objects'], labels_predicted, color="green", linewidth=1)
        # plt.xticks(())
        # plt.yticks(())
        # plt.show()